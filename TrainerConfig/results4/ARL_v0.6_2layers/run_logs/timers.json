{
    "name": "root",
    "gauges": {
        "Solver.Policy.Entropy.mean": {
            "value": 0.2954019606113434,
            "min": 0.2778540253639221,
            "max": 0.44901683926582336,
            "count": 98
        },
        "Solver.Policy.Entropy.sum": {
            "value": 255.227294921875,
            "min": 246.83047485351562,
            "max": 523.531005859375,
            "count": 98
        },
        "Solver.Environment.EpisodeLength.mean": {
            "value": 39.0,
            "min": 31.74074074074074,
            "max": 39.0,
            "count": 98
        },
        "Solver.Environment.EpisodeLength.sum": {
            "value": 975.0,
            "min": 607.0,
            "max": 1085.0,
            "count": 98
        },
        "Solver.Step.mean": {
            "value": 121965.0,
            "min": 24982.0,
            "max": 121965.0,
            "count": 98
        },
        "Solver.Step.sum": {
            "value": 121965.0,
            "min": 24982.0,
            "max": 121965.0,
            "count": 98
        },
        "Solver.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.8791747093200684,
            "min": -0.08666428178548813,
            "max": 0.9173830151557922,
            "count": 98
        },
        "Solver.Policy.ExtrinsicValueEstimate.sum": {
            "value": 21.979368209838867,
            "min": -2.599928379058838,
            "max": 23.600082397460938,
            "count": 98
        },
        "Solver.Environment.CumulativeReward.mean": {
            "value": 0.42112003147602084,
            "min": 0.017866686979929606,
            "max": 0.4690400326251984,
            "count": 98
        },
        "Solver.Environment.CumulativeReward.sum": {
            "value": 10.52800078690052,
            "min": 0.291000172495842,
            "max": 11.726000815629959,
            "count": 98
        },
        "Solver.Policy.ExtrinsicReward.mean": {
            "value": 0.42112003147602084,
            "min": 0.017866686979929606,
            "max": 0.4690400326251984,
            "count": 98
        },
        "Solver.Policy.ExtrinsicReward.sum": {
            "value": 10.52800078690052,
            "min": 0.291000172495842,
            "max": 11.726000815629959,
            "count": 98
        },
        "Solver.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 98
        },
        "Solver.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 98
        },
        "Solver.Losses.PolicyLoss.mean": {
            "value": 0.06447684733817975,
            "min": 0.053876478651848934,
            "max": 0.08355177950579673,
            "count": 46
        },
        "Solver.Losses.PolicyLoss.sum": {
            "value": 0.06447684733817975,
            "min": 0.053876478651848934,
            "max": 0.08355177950579673,
            "count": 46
        },
        "Solver.Losses.ValueLoss.mean": {
            "value": 0.006484721345865789,
            "min": 0.00408803465446302,
            "max": 0.05315545469056815,
            "count": 46
        },
        "Solver.Losses.ValueLoss.sum": {
            "value": 0.006484721345865789,
            "min": 0.00408803465446302,
            "max": 0.05315545469056815,
            "count": 46
        },
        "Solver.Policy.LearningRate.mean": {
            "value": 0.0002279226240258,
            "min": 0.0002279226240258,
            "max": 0.000284037005321,
            "count": 46
        },
        "Solver.Policy.LearningRate.sum": {
            "value": 0.0002279226240258,
            "min": 0.0002279226240258,
            "max": 0.000284037005321,
            "count": 46
        },
        "Solver.Policy.Epsilon.mean": {
            "value": 0.1759742,
            "min": 0.1759742,
            "max": 0.19467900000000002,
            "count": 46
        },
        "Solver.Policy.Epsilon.sum": {
            "value": 0.1759742,
            "min": 0.1759742,
            "max": 0.19467900000000002,
            "count": 46
        },
        "Solver.Policy.Beta.mean": {
            "value": 0.0038011125800000004,
            "min": 0.0038011125800000004,
            "max": 0.0047344821,
            "count": 46
        },
        "Solver.Policy.Beta.sum": {
            "value": 0.0038011125800000004,
            "min": 0.0038011125800000004,
            "max": 0.0047344821,
            "count": 46
        },
        "Generator.Policy.Entropy.mean": {
            "value": 1.51416015625,
            "min": 1.5121879577636719,
            "max": 1.5146255493164062,
            "count": 6
        },
        "Generator.Policy.Entropy.sum": {
            "value": 1524.75927734375,
            "min": 1497.244140625,
            "max": 1744.8486328125,
            "count": 6
        },
        "Generator.Environment.EpisodeLength.mean": {
            "value": 10.869047619047619,
            "min": 10.616279069767442,
            "max": 11.0,
            "count": 6
        },
        "Generator.Environment.EpisodeLength.sum": {
            "value": 913.0,
            "min": 891.0,
            "max": 924.0,
            "count": 6
        },
        "Generator.Step.mean": {
            "value": 36989.0,
            "min": 31992.0,
            "max": 36989.0,
            "count": 6
        },
        "Generator.Step.sum": {
            "value": 36989.0,
            "min": 31992.0,
            "max": 36989.0,
            "count": 6
        },
        "Generator.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.27011969685554504,
            "min": 0.22394900023937225,
            "max": 0.29049158096313477,
            "count": 6
        },
        "Generator.Policy.ExtrinsicValueEstimate.sum": {
            "value": 22.690053939819336,
            "min": 18.811716079711914,
            "max": 24.982275009155273,
            "count": 6
        },
        "Generator.Environment.CumulativeReward.mean": {
            "value": 0.5292354104375201,
            "min": 0.5266982895906928,
            "max": 0.561214043200016,
            "count": 6
        },
        "Generator.Environment.CumulativeReward.sum": {
            "value": 44.455774476751685,
            "min": 44.455774476751685,
            "max": 45.86445811390877,
            "count": 6
        },
        "Generator.Policy.ExtrinsicReward.mean": {
            "value": 0.5292354104375201,
            "min": 0.5266982895906928,
            "max": 0.561214043200016,
            "count": 6
        },
        "Generator.Policy.ExtrinsicReward.sum": {
            "value": 44.455774476751685,
            "min": 44.455774476751685,
            "max": 45.86445811390877,
            "count": 6
        },
        "Generator.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 6
        },
        "Generator.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 6
        },
        "Generator.Losses.PolicyLoss.mean": {
            "value": 0.07813956549337793,
            "min": 0.0729213856854282,
            "max": 0.07813956549337793,
            "count": 2
        },
        "Generator.Losses.PolicyLoss.sum": {
            "value": 0.07813956549337793,
            "min": 0.0729213856854282,
            "max": 0.07813956549337793,
            "count": 2
        },
        "Generator.Losses.ValueLoss.mean": {
            "value": 0.0072931516818547,
            "min": 0.0072931516818547,
            "max": 0.03769846357560406,
            "count": 2
        },
        "Generator.Losses.ValueLoss.sum": {
            "value": 0.0072931516818547,
            "min": 0.0072931516818547,
            "max": 0.03769846357560406,
            "count": 2
        },
        "Generator.Policy.LearningRate.mean": {
            "value": 0.0007994378080702741,
            "min": 0.0007994378080702741,
            "max": 0.0007994706560661681,
            "count": 2
        },
        "Generator.Policy.LearningRate.sum": {
            "value": 0.0007994378080702741,
            "min": 0.0007994378080702741,
            "max": 0.0007994706560661681,
            "count": 2
        },
        "Generator.Policy.Epsilon.mean": {
            "value": 0.199929726,
            "min": 0.199929726,
            "max": 0.199933832,
            "count": 2
        },
        "Generator.Policy.Epsilon.sum": {
            "value": 0.199929726,
            "min": 0.199929726,
            "max": 0.199933832,
            "count": 2
        },
        "Generator.Policy.Beta.mean": {
            "value": 0.0049964933274,
            "min": 0.0049964933274,
            "max": 0.0049966982168,
            "count": 2
        },
        "Generator.Policy.Beta.sum": {
            "value": 0.0049964933274,
            "min": 0.0049964933274,
            "max": 0.0049966982168,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1682284336",
        "python_version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]",
        "command_line_arguments": "/home/bears_bears/Unity_env/bin/mlagents-learn ARLPCG.yaml --run-id ARL_v0.6_2layers --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cu102",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1682284713"
    },
    "total": 376.87185391798266,
    "count": 1,
    "self": 0.011724915966624394,
    "children": {
        "run_training.setup": {
            "total": 0.04904802801320329,
            "count": 1,
            "self": 0.04904802801320329
        },
        "TrainerController.start_learning": {
            "total": 376.81108097400283,
            "count": 1,
            "self": 0.3578803554701153,
            "children": {
                "TrainerController._reset_env": {
                    "total": 46.76514546899125,
                    "count": 1,
                    "self": 46.76514546899125
                },
                "TrainerController.advance": {
                    "total": 329.5298008515383,
                    "count": 11867,
                    "self": 0.4483645801083185,
                    "children": {
                        "env_step": {
                            "total": 273.38907396193827,
                            "count": 11867,
                            "self": 250.5606335538614,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 22.622171219612937,
                                    "count": 11867,
                                    "self": 1.4250003055494744,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 21.197170914063463,
                                            "count": 12106,
                                            "self": 21.197170914063463
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.20626918846392073,
                                    "count": 11866,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 314.9122319369344,
                                            "count": 11866,
                                            "is_parallel": true,
                                            "self": 146.82722654379904,
                                            "children": {
                                                "run_training.setup": {
                                                    "total": 0.0,
                                                    "count": 0,
                                                    "is_parallel": true,
                                                    "self": 0.0,
                                                    "children": {
                                                        "steps_from_proto": {
                                                            "total": 0.0015290880110114813,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0006273569888435304,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.0009017310221679509,
                                                                    "count": 6,
                                                                    "is_parallel": true,
                                                                    "self": 0.0009017310221679509
                                                                }
                                                            }
                                                        },
                                                        "UnityEnvironment.step": {
                                                            "total": 0.7889406299800612,
                                                            "count": 1,
                                                            "is_parallel": true,
                                                            "self": 0.0002636730205267668,
                                                            "children": {
                                                                "UnityEnvironment._generate_step_input": {
                                                                    "total": 0.0005432309990283102,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.0005432309990283102
                                                                },
                                                                "communicator.exchange": {
                                                                    "total": 0.7874423819885124,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.7874423819885124
                                                                },
                                                                "steps_from_proto": {
                                                                    "total": 0.0006913439719937742,
                                                                    "count": 2,
                                                                    "is_parallel": true,
                                                                    "self": 0.0003531419497448951,
                                                                    "children": {
                                                                        "_process_rank_one_or_two_observation": {
                                                                            "total": 0.0003382020222488791,
                                                                            "count": 6,
                                                                            "is_parallel": true,
                                                                            "self": 0.0003382020222488791
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 168.08500539313536,
                                                    "count": 11865,
                                                    "is_parallel": true,
                                                    "self": 3.146548338641878,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 3.0939439317735378,
                                                            "count": 11865,
                                                            "is_parallel": true,
                                                            "self": 3.0939439317735378
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 153.62328763541882,
                                                            "count": 11865,
                                                            "is_parallel": true,
                                                            "self": 153.62328763541882
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 8.221225487301126,
                                                            "count": 23730,
                                                            "is_parallel": true,
                                                            "self": 3.6699308631941676,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 4.5512946241069585,
                                                                    "count": 71190,
                                                                    "is_parallel": true,
                                                                    "self": 4.5512946241069585
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 55.69236230949173,
                            "count": 23732,
                            "self": 0.6831074172805529,
                            "children": {
                                "process_trajectory": {
                                    "total": 13.771259106200887,
                                    "count": 23732,
                                    "self": 13.586977668193867,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.18428143800701946,
                                            "count": 2,
                                            "self": 0.18428143800701946
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 41.23799578601029,
                                    "count": 50,
                                    "self": 20.03465693225735,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 21.20333885375294,
                                            "count": 2400,
                                            "self": 21.20333885375294
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.1582542980031576,
                    "count": 1,
                    "self": 0.001550553017295897,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.1567037449858617,
                            "count": 2,
                            "self": 0.1567037449858617
                        }
                    }
                }
            }
        }
    }
}