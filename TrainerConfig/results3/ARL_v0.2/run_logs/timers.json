{
    "name": "root",
    "gauges": {
        "Solver.Policy.Entropy.mean": {
            "value": 0.10547430068254471,
            "min": 0.09292110055685043,
            "max": 0.6925841569900513,
            "count": 103
        },
        "Solver.Policy.Entropy.sum": {
            "value": 99.56774139404297,
            "min": 90.69099426269531,
            "max": 742.4476928710938,
            "count": 103
        },
        "Solver.Environment.EpisodeLength.mean": {
            "value": 138.9090909090909,
            "min": 11.987012987012987,
            "max": 162.71428571428572,
            "count": 103
        },
        "Solver.Environment.EpisodeLength.sum": {
            "value": 1528.0,
            "min": 336.0,
            "max": 1528.0,
            "count": 103
        },
        "Solver.Step.mean": {
            "value": 102970.0,
            "min": 988.0,
            "max": 102970.0,
            "count": 103
        },
        "Solver.Step.sum": {
            "value": 102970.0,
            "min": 988.0,
            "max": 102970.0,
            "count": 103
        },
        "Solver.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.0015673637390137,
            "min": -0.7929221987724304,
            "max": 1.0015673637390137,
            "count": 103
        },
        "Solver.Policy.ExtrinsicValueEstimate.sum": {
            "value": 21.032915115356445,
            "min": -39.24089813232422,
            "max": 21.032915115356445,
            "count": 103
        },
        "Solver.Environment.CumulativeReward.mean": {
            "value": 2.1698182171041314,
            "min": -0.939999991341641,
            "max": 2.8175714782306125,
            "count": 103
        },
        "Solver.Environment.CumulativeReward.sum": {
            "value": 23.868000388145447,
            "min": -72.34999942779541,
            "max": 23.868000388145447,
            "count": 103
        },
        "Solver.Policy.ExtrinsicReward.mean": {
            "value": 2.1698182171041314,
            "min": -0.939999991341641,
            "max": 2.8175714782306125,
            "count": 103
        },
        "Solver.Policy.ExtrinsicReward.sum": {
            "value": 23.868000388145447,
            "min": -72.34999942779541,
            "max": 23.868000388145447,
            "count": 103
        },
        "Solver.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 103
        },
        "Solver.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 103
        },
        "Generator.Policy.Entropy.mean": {
            "value": 1.3711516857147217,
            "min": 1.3711516857147217,
            "max": 1.4232137203216553,
            "count": 19
        },
        "Generator.Policy.Entropy.sum": {
            "value": 1368.409423828125,
            "min": 1368.409423828125,
            "max": 1636.0361328125,
            "count": 19
        },
        "Generator.Environment.EpisodeLength.mean": {
            "value": 8.415094339622641,
            "min": 4.5054945054945055,
            "max": 8.415094339622641,
            "count": 19
        },
        "Generator.Environment.EpisodeLength.sum": {
            "value": 892.0,
            "min": 818.0,
            "max": 892.0,
            "count": 19
        },
        "Generator.Step.mean": {
            "value": 18993.0,
            "min": 998.0,
            "max": 18993.0,
            "count": 19
        },
        "Generator.Step.sum": {
            "value": 18993.0,
            "min": 998.0,
            "max": 18993.0,
            "count": 19
        },
        "Generator.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.1887438297271729,
            "min": -8.641691207885742,
            "max": 1.1887438297271729,
            "count": 19
        },
        "Generator.Policy.ExtrinsicValueEstimate.sum": {
            "value": 126.00684356689453,
            "min": -1439.227783203125,
            "max": 126.00684356689453,
            "count": 19
        },
        "Generator.Environment.CumulativeReward.mean": {
            "value": 2.0603925271205745,
            "min": 0.22428572100106176,
            "max": 2.0603925271205745,
            "count": 19
        },
        "Generator.Environment.CumulativeReward.sum": {
            "value": 218.4016078747809,
            "min": 40.82000122219324,
            "max": 218.4016078747809,
            "count": 19
        },
        "Generator.Policy.ExtrinsicReward.mean": {
            "value": 2.0603925271205745,
            "min": 0.22428572100106176,
            "max": 2.0603925271205745,
            "count": 19
        },
        "Generator.Policy.ExtrinsicReward.sum": {
            "value": 218.4016078747809,
            "min": 40.82000122219324,
            "max": 218.4016078747809,
            "count": 19
        },
        "Generator.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 19
        },
        "Generator.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 19
        },
        "Solver.Losses.PolicyLoss.mean": {
            "value": 0.06342650075242215,
            "min": 0.05239650440247109,
            "max": 0.08386862735884885,
            "count": 49
        },
        "Solver.Losses.PolicyLoss.sum": {
            "value": 0.06342650075242215,
            "min": 0.05239650440247109,
            "max": 0.08386862735884885,
            "count": 49
        },
        "Solver.Losses.ValueLoss.mean": {
            "value": 0.07358446067162588,
            "min": 0.004384538221832675,
            "max": 0.1256214395786325,
            "count": 49
        },
        "Solver.Losses.ValueLoss.sum": {
            "value": 0.07358446067162588,
            "min": 0.004384538221832675,
            "max": 0.1256214395786325,
            "count": 49
        },
        "Solver.Policy.LearningRate.mean": {
            "value": 0.00023885642038119998,
            "min": 0.00023885642038119998,
            "max": 0.00029876580041139996,
            "count": 49
        },
        "Solver.Policy.LearningRate.sum": {
            "value": 0.00023885642038119998,
            "min": 0.00023885642038119998,
            "max": 0.00029876580041139996,
            "count": 49
        },
        "Solver.Policy.Epsilon.mean": {
            "value": 0.17961880000000005,
            "min": 0.17961880000000005,
            "max": 0.1995886,
            "count": 49
        },
        "Solver.Policy.Epsilon.sum": {
            "value": 0.17961880000000005,
            "min": 0.17961880000000005,
            "max": 0.1995886,
            "count": 49
        },
        "Solver.Policy.Beta.mean": {
            "value": 0.00040013212,
            "min": 0.00040013212,
            "max": 0.0004979841400000001,
            "count": 49
        },
        "Solver.Policy.Beta.sum": {
            "value": 0.00040013212,
            "min": 0.00040013212,
            "max": 0.0004979841400000001,
            "count": 49
        },
        "Generator.Losses.PolicyLoss.mean": {
            "value": 0.058675388114352245,
            "min": 0.058675388114352245,
            "max": 0.07490071031497791,
            "count": 9
        },
        "Generator.Losses.PolicyLoss.sum": {
            "value": 0.058675388114352245,
            "min": 0.058675388114352245,
            "max": 0.07490071031497791,
            "count": 9
        },
        "Generator.Losses.ValueLoss.mean": {
            "value": 1.5491218095024426,
            "min": 0.47285983618348837,
            "max": 42.70592753092448,
            "count": 9
        },
        "Generator.Losses.ValueLoss.sum": {
            "value": 1.5491218095024426,
            "min": 0.47285983618348837,
            "max": 42.70592753092448,
            "count": 9
        },
        "Generator.Policy.LearningRate.mean": {
            "value": 0.0007704144036982001,
            "min": 0.0007704144036982001,
            "max": 0.0007967072004116,
            "count": 9
        },
        "Generator.Policy.LearningRate.sum": {
            "value": 0.0007704144036982001,
            "min": 0.0007704144036982001,
            "max": 0.0007967072004116,
            "count": 9
        },
        "Generator.Policy.Epsilon.mean": {
            "value": 0.19630180000000005,
            "min": 0.19630180000000005,
            "max": 0.1995884,
            "count": 9
        },
        "Generator.Policy.Epsilon.sum": {
            "value": 0.19630180000000005,
            "min": 0.19630180000000005,
            "max": 0.1995884,
            "count": 9
        },
        "Generator.Policy.Beta.mean": {
            "value": 0.0009633878200000001,
            "min": 0.0009633878200000001,
            "max": 0.00099592516,
            "count": 9
        },
        "Generator.Policy.Beta.sum": {
            "value": 0.0009633878200000001,
            "min": 0.0009633878200000001,
            "max": 0.00099592516,
            "count": 9
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1682274232",
        "python_version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]",
        "command_line_arguments": "/home/bears_bears/Unity_env/bin/mlagents-learn ARLPCG.yaml --run-id ARL_v0.2 --force",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cu102",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1682275058"
    },
    "total": 825.4855807659915,
    "count": 1,
    "self": 0.009502711007371545,
    "children": {
        "run_training.setup": {
            "total": 0.03277972599607892,
            "count": 1,
            "self": 0.03277972599607892
        },
        "TrainerController.start_learning": {
            "total": 825.443298328988,
            "count": 1,
            "self": 0.5497808385989629,
            "children": {
                "TrainerController._reset_env": {
                    "total": 31.075342437979998,
                    "count": 1,
                    "self": 31.075342437979998
                },
                "TrainerController.advance": {
                    "total": 793.6424959513824,
                    "count": 16950,
                    "self": 0.6985593949211761,
                    "children": {
                        "env_step": {
                            "total": 722.9757049834006,
                            "count": 16950,
                            "self": 686.6020918912545,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 36.00808726053219,
                                    "count": 16950,
                                    "self": 2.3554580603085924,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 33.6526292002236,
                                            "count": 19736,
                                            "self": 33.6526292002236
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.3655258316139225,
                                    "count": 16949,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 813.3559700068436,
                                            "count": 16949,
                                            "is_parallel": true,
                                            "self": 168.6300173633208,
                                            "children": {
                                                "run_training.setup": {
                                                    "total": 0.0,
                                                    "count": 0,
                                                    "is_parallel": true,
                                                    "self": 0.0,
                                                    "children": {
                                                        "steps_from_proto": {
                                                            "total": 0.0016096089966595173,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0006269890000112355,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.0009826199966482818,
                                                                    "count": 6,
                                                                    "is_parallel": true,
                                                                    "self": 0.0009826199966482818
                                                                }
                                                            }
                                                        },
                                                        "UnityEnvironment.step": {
                                                            "total": 0.5710811750032008,
                                                            "count": 1,
                                                            "is_parallel": true,
                                                            "self": 0.0002995239628944546,
                                                            "children": {
                                                                "UnityEnvironment._generate_step_input": {
                                                                    "total": 0.0011083360004704446,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.0011083360004704446
                                                                },
                                                                "communicator.exchange": {
                                                                    "total": 0.5687518200138584,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.5687518200138584
                                                                },
                                                                "steps_from_proto": {
                                                                    "total": 0.0009214950259774923,
                                                                    "count": 2,
                                                                    "is_parallel": true,
                                                                    "self": 0.0004665360611397773,
                                                                    "children": {
                                                                        "_process_rank_one_or_two_observation": {
                                                                            "total": 0.00045495896483771503,
                                                                            "count": 6,
                                                                            "is_parallel": true,
                                                                            "self": 0.00045495896483771503
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 644.7259526435228,
                                                    "count": 16948,
                                                    "is_parallel": true,
                                                    "self": 4.463782279373845,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 4.309176442096941,
                                                            "count": 16948,
                                                            "is_parallel": true,
                                                            "self": 4.309176442096941
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 623.939046725136,
                                                            "count": 16948,
                                                            "is_parallel": true,
                                                            "self": 623.939046725136
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 12.013947196915979,
                                                            "count": 33896,
                                                            "is_parallel": true,
                                                            "self": 5.73980918203597,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 6.274138014880009,
                                                                    "count": 101688,
                                                                    "is_parallel": true,
                                                                    "self": 6.274138014880009
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 69.96823157306062,
                            "count": 33898,
                            "self": 1.008866386837326,
                            "children": {
                                "process_trajectory": {
                                    "total": 20.004826909396797,
                                    "count": 33898,
                                    "self": 19.829831109411316,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.17499579998548143,
                                            "count": 2,
                                            "self": 0.17499579998548143
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 48.9545382768265,
                                    "count": 58,
                                    "self": 23.60988471773453,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 25.344653559091967,
                                            "count": 2787,
                                            "self": 25.344653559091967
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.110006218776107e-06,
                    "count": 1,
                    "self": 3.110006218776107e-06
                },
                "TrainerController._save_models": {
                    "total": 0.17567599102039821,
                    "count": 1,
                    "self": 0.0012629709963221103,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.1744130200240761,
                            "count": 2,
                            "self": 0.1744130200240761
                        }
                    }
                }
            }
        }
    }
}