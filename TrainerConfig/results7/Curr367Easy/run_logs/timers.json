{
    "name": "root",
    "gauges": {
        "Generator.Policy.Entropy.mean": {
            "value": 1.4216974973678589,
            "min": 1.4189382791519165,
            "max": 1.4216974973678589,
            "count": 26
        },
        "Generator.Policy.Entropy.sum": {
            "value": 355.42437744140625,
            "min": 344.8020324707031,
            "max": 368.9239807128906,
            "count": 26
        },
        "Generator.theta.mean": {
            "value": -26.0554247424897,
            "min": -27.541578898710362,
            "max": -8.254257717228029,
            "count": 26
        },
        "Generator.theta.sum": {
            "value": -6539.911610364914,
            "min": -7023.102619171143,
            "max": -2113.0899756103754,
            "count": 26
        },
        "Generator.height.mean": {
            "value": 2.93283148590787,
            "min": 2.93283148590787,
            "max": 3.0521454158283414,
            "count": 26
        },
        "Generator.height.sum": {
            "value": 736.1407029628754,
            "min": 726.5428187847137,
            "max": 776.729501247406,
            "count": 26
        },
        "Generator.distance.mean": {
            "value": 2.076966426761977,
            "min": 2.018763096457026,
            "max": 2.105055228112236,
            "count": 26
        },
        "Generator.distance.sum": {
            "value": 521.3185731172562,
            "min": 500.5276999473572,
            "max": 548.522579908371,
            "count": 26
        },
        "Generator.Y_difference.mean": {
            "value": -1.6934583745952474,
            "min": -1.7071434521482738,
            "max": -0.49304564603153267,
            "count": 26
        },
        "Generator.Y_difference.sum": {
            "value": -425.0580520234071,
            "min": -432.58771346509457,
            "max": -126.21968538407236,
            "count": 26
        },
        "Generator.Environment.LessonNumber.n_obstacles.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 26
        },
        "Generator.Environment.LessonNumber.n_obstacles.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 26
        },
        "Generator.Environment.LessonNumber.aux_input.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 26
        },
        "Generator.Environment.LessonNumber.aux_input.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 26
        },
        "Generator.Environment.EpisodeLength.mean": {
            "value": 1.7555555555555555,
            "min": 0.10619469026548672,
            "max": 1.7555555555555555,
            "count": 26
        },
        "Generator.Environment.EpisodeLength.sum": {
            "value": 158.0,
            "min": 24.0,
            "max": 158.0,
            "count": 26
        },
        "Generator.Step.mean": {
            "value": 6498.0,
            "min": 249.0,
            "max": 6498.0,
            "count": 26
        },
        "Generator.Step.sum": {
            "value": 6498.0,
            "min": 249.0,
            "max": 6498.0,
            "count": 26
        },
        "Generator.Policy.ExtrinsicValueEstimate.mean": {
            "value": -2.0617387294769287,
            "min": -4.4251813888549805,
            "max": -0.49856463074684143,
            "count": 26
        },
        "Generator.Policy.ExtrinsicValueEstimate.sum": {
            "value": -185.55648803710938,
            "min": -442.5181579589844,
            "max": -109.18565368652344,
            "count": 26
        },
        "Generator.Environment.CumulativeReward.mean": {
            "value": -0.8228777456614706,
            "min": -0.8980582642448323,
            "max": -0.8228777456614706,
            "count": 26
        },
        "Generator.Environment.CumulativeReward.sum": {
            "value": -74.05899710953236,
            "min": -201.67299234867096,
            "max": -74.05899710953236,
            "count": 26
        },
        "Generator.Policy.ExtrinsicReward.mean": {
            "value": -0.8228777456614706,
            "min": -0.8980582642448323,
            "max": -0.8228777456614706,
            "count": 26
        },
        "Generator.Policy.ExtrinsicReward.sum": {
            "value": -74.05899710953236,
            "min": -201.67299234867096,
            "max": -74.05899710953236,
            "count": 26
        },
        "Generator.Score.mean": {
            "value": 1.6687116564417177,
            "min": 1.0,
            "max": 1.6687116564417177,
            "count": 26
        },
        "Generator.Score.sum": {
            "value": 272.0,
            "min": 26.0,
            "max": 272.0,
            "count": 26
        },
        "Generator.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 26
        },
        "Generator.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 26
        },
        "Generator.Losses.PolicyLoss.mean": {
            "value": 0.0820627383266886,
            "min": 0.0820627383266886,
            "max": 0.0820627383266886,
            "count": 1
        },
        "Generator.Losses.PolicyLoss.sum": {
            "value": 0.0820627383266886,
            "min": 0.0820627383266886,
            "max": 0.0820627383266886,
            "count": 1
        },
        "Generator.Losses.ValueLoss.mean": {
            "value": 15.886301040649414,
            "min": 15.886301040649414,
            "max": 15.886301040649414,
            "count": 1
        },
        "Generator.Losses.ValueLoss.sum": {
            "value": 15.886301040649414,
            "min": 15.886301040649414,
            "max": 15.886301040649414,
            "count": 1
        },
        "Generator.Policy.LearningRate.mean": {
            "value": 0.0008633666803299999,
            "min": 0.0008633666803299999,
            "max": 0.0008633666803299999,
            "count": 1
        },
        "Generator.Policy.LearningRate.sum": {
            "value": 0.0008633666803299999,
            "min": 0.0008633666803299999,
            "max": 0.0008633666803299999,
            "count": 1
        },
        "Generator.Policy.Epsilon.mean": {
            "value": 0.18633666666666668,
            "min": 0.18633666666666668,
            "max": 0.18633666666666668,
            "count": 1
        },
        "Generator.Policy.Epsilon.sum": {
            "value": 0.18633666666666668,
            "min": 0.18633666666666668,
            "max": 0.18633666666666668,
            "count": 1
        },
        "Generator.Policy.Beta.mean": {
            "value": 0.000605723,
            "min": 0.000605723,
            "max": 0.000605723,
            "count": 1
        },
        "Generator.Policy.Beta.sum": {
            "value": 0.000605723,
            "min": 0.000605723,
            "max": 0.000605723,
            "count": 1
        },
        "Solver.Policy.Entropy.mean": {
            "value": 0.16159629821777344,
            "min": 0.15400780737400055,
            "max": 0.6930838227272034,
            "count": 154
        },
        "Solver.Policy.Entropy.sum": {
            "value": 192.29959106445312,
            "min": 25.73084831237793,
            "max": 981.2711181640625,
            "count": 154
        },
        "Solver.theta.mean": {
            "value": -27.876192139727728,
            "min": -44.946164512634276,
            "max": -5.133642864227295,
            "count": 153
        },
        "Solver.theta.sum": {
            "value": -1561.0667598247528,
            "min": -2217.6626014709473,
            "max": -51.33642864227295,
            "count": 153
        },
        "Solver.height.mean": {
            "value": 2.974603431565421,
            "min": 2.8192408800125124,
            "max": 3.1666143894195558,
            "count": 153
        },
        "Solver.height.sum": {
            "value": 166.57779216766357,
            "min": 14.919271469116211,
            "max": 248.81001472473145,
            "count": 153
        },
        "Solver.distance.mean": {
            "value": 2.0617963735546385,
            "min": 1.8938410997390747,
            "max": 2.1939027309417725,
            "count": 153
        },
        "Solver.distance.sum": {
            "value": 115.46059691905975,
            "min": 10.969513654708862,
            "max": 162.76105213165283,
            "count": 153
        },
        "Solver.Y_difference.mean": {
            "value": -1.8035870512415255,
            "min": -2.698320005621229,
            "max": -0.308412966132164,
            "count": 153
        },
        "Solver.Y_difference.sum": {
            "value": -101.00087486952543,
            "min": -137.58147358894348,
            "max": -3.08412966132164,
            "count": 153
        },
        "Solver.Environment.LessonNumber.n_obstacles.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 154
        },
        "Solver.Environment.LessonNumber.n_obstacles.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 154
        },
        "Solver.Environment.LessonNumber.aux_input.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 154
        },
        "Solver.Environment.LessonNumber.aux_input.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 154
        },
        "Solver.Environment.EpisodeLength.mean": {
            "value": 55.61904761904762,
            "min": 20.142857142857142,
            "max": 88.57142857142857,
            "count": 153
        },
        "Solver.Environment.EpisodeLength.sum": {
            "value": 1168.0,
            "min": 56.0,
            "max": 1868.0,
            "count": 153
        },
        "Solver.Step.mean": {
            "value": 153998.0,
            "min": 996.0,
            "max": 153998.0,
            "count": 154
        },
        "Solver.Step.sum": {
            "value": 153998.0,
            "min": 996.0,
            "max": 153998.0,
            "count": 154
        },
        "Solver.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.045493945479393005,
            "min": -0.8470067381858826,
            "max": 0.3252333104610443,
            "count": 154
        },
        "Solver.Policy.ExtrinsicValueEstimate.sum": {
            "value": 1.1373486518859863,
            "min": -38.962310791015625,
            "max": 6.829899787902832,
            "count": 154
        },
        "Solver.Policy.CuriosityValueEstimate.mean": {
            "value": 0.0022692447528243065,
            "min": -0.006099365185946226,
            "max": 0.051159728318452835,
            "count": 154
        },
        "Solver.Policy.CuriosityValueEstimate.sum": {
            "value": 0.05673111975193024,
            "min": -0.15858349204063416,
            "max": 2.4045071601867676,
            "count": 154
        },
        "Solver.Environment.CumulativeReward.mean": {
            "value": -0.3318888851337963,
            "min": -0.8956382883355972,
            "max": 0.2685833436747392,
            "count": 154
        },
        "Solver.Environment.CumulativeReward.sum": {
            "value": -5.973999932408333,
            "min": -42.09499955177307,
            "max": 3.2230001240968704,
            "count": 154
        },
        "Solver.Policy.ExtrinsicReward.mean": {
            "value": -0.3318888851337963,
            "min": -0.8956382883355972,
            "max": 0.2685833436747392,
            "count": 154
        },
        "Solver.Policy.ExtrinsicReward.sum": {
            "value": -5.973999932408333,
            "min": -42.09499955177307,
            "max": 3.2230001240968704,
            "count": 154
        },
        "Solver.Policy.CuriosityReward.mean": {
            "value": 0.0008663655159277065,
            "min": 0.0,
            "max": 0.004859393967005114,
            "count": 154
        },
        "Solver.Policy.CuriosityReward.sum": {
            "value": 0.015594579286698718,
            "min": 0.0,
            "max": 0.12862550088902935,
            "count": 154
        },
        "Solver.Score.mean": {
            "value": 1.5588235294117647,
            "min": 1.0,
            "max": 2.0555555555555554,
            "count": 154
        },
        "Solver.Score.sum": {
            "value": 53.0,
            "min": 1.0,
            "max": 90.0,
            "count": 154
        },
        "Solver.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 154
        },
        "Solver.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 154
        },
        "Solver.Losses.PolicyLoss.mean": {
            "value": 0.15981700184056535,
            "min": 0.12606885024191192,
            "max": 0.15981700184056535,
            "count": 74
        },
        "Solver.Losses.PolicyLoss.sum": {
            "value": 0.15981700184056535,
            "min": 0.12606885024191192,
            "max": 0.15981700184056535,
            "count": 74
        },
        "Solver.Losses.ValueLoss.mean": {
            "value": 0.03282329731640251,
            "min": 0.00031841489396811085,
            "max": 0.03787492133657603,
            "count": 74
        },
        "Solver.Losses.ValueLoss.sum": {
            "value": 0.03282329731640251,
            "min": 0.00031841489396811085,
            "max": 0.03787492133657603,
            "count": 74
        },
        "Solver.Policy.LearningRate.mean": {
            "value": 0.0009778400511080002,
            "min": 0.0009778400511080002,
            "max": 0.001986266667353333,
            "count": 74
        },
        "Solver.Policy.LearningRate.sum": {
            "value": 0.0009778400511080002,
            "min": 0.0009778400511080002,
            "max": 0.001986266667353333,
            "count": 74
        },
        "Solver.Policy.Epsilon.mean": {
            "value": 0.14889200000000002,
            "min": 0.14889200000000002,
            "max": 0.19931333333333337,
            "count": 74
        },
        "Solver.Policy.Epsilon.sum": {
            "value": 0.14889200000000002,
            "min": 0.14889200000000002,
            "max": 0.19931333333333337,
            "count": 74
        },
        "Solver.Policy.Beta.mean": {
            "value": 0.0004940308,
            "min": 0.0004940308,
            "max": 0.000993202,
            "count": 74
        },
        "Solver.Policy.Beta.sum": {
            "value": 0.0004940308,
            "min": 0.0004940308,
            "max": 0.000993202,
            "count": 74
        },
        "Solver.Losses.CuriosityForwardLoss.mean": {
            "value": 0.02205598454020219,
            "min": 0.0025899449760356965,
            "max": 0.15443303864837313,
            "count": 74
        },
        "Solver.Losses.CuriosityForwardLoss.sum": {
            "value": 0.02205598454020219,
            "min": 0.0025899449760356965,
            "max": 0.15443303864837313,
            "count": 74
        },
        "Solver.Losses.CuriosityInverseLoss.mean": {
            "value": 0.027774479454592438,
            "min": 8.740521266307229e-05,
            "max": 0.46054687719636905,
            "count": 74
        },
        "Solver.Losses.CuriosityInverseLoss.sum": {
            "value": 0.027774479454592438,
            "min": 8.740521266307229e-05,
            "max": 0.46054687719636905,
            "count": 74
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1683466162",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Kevinn\\test_ml_env\\Scripts\\mlagents-learn easy.yaml --num-envs=7 --run-id=Curr367Easy --env=Z:\\Git\\Flappy_bird\\Builds\\Windows\\Curr37\\Flappy_bird.exe --no-graphics --torch-device=cuda --time-scale=3 --base-port=5000",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.0.1+cu118",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1683467031"
    },
    "total": 868.6849281,
    "count": 1,
    "self": 10.01301639999997,
    "children": {
        "run_training.setup": {
            "total": 1.4887063999999999,
            "count": 1,
            "self": 1.4887063999999999
        },
        "TrainerController.start_learning": {
            "total": 857.1832053,
            "count": 1,
            "self": 1.7275918000017327,
            "children": {
                "TrainerController._reset_env": {
                    "total": 5.102410300000001,
                    "count": 1,
                    "self": 5.102410300000001
                },
                "TrainerController.advance": {
                    "total": 850.1137933999983,
                    "count": 27455,
                    "self": 1.4253317000067227,
                    "children": {
                        "env_step": {
                            "total": 836.6160186999889,
                            "count": 27455,
                            "self": 235.4081503999871,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 599.7128916999961,
                                    "count": 161911,
                                    "self": 11.170000700005176,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 588.542890999991,
                                            "count": 161645,
                                            "self": 588.542890999991
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.4949766000056322,
                                    "count": 27454,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 5944.0988501000675,
                                            "count": 161897,
                                            "is_parallel": true,
                                            "self": 5481.343266200077,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.009107100000347312,
                                                    "count": 28,
                                                    "is_parallel": true,
                                                    "self": 0.00455790000035039,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.004549199999996922,
                                                            "count": 112,
                                                            "is_parallel": true,
                                                            "self": 0.004549199999996922
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 462.74647679999015,
                                                    "count": 161897,
                                                    "is_parallel": true,
                                                    "self": 18.007185699950867,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 10.582901600026293,
                                                            "count": 161897,
                                                            "is_parallel": true,
                                                            "self": 10.582901600026293
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 377.32084830001,
                                                            "count": 161897,
                                                            "is_parallel": true,
                                                            "self": 377.32084830001
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 56.83554120000295,
                                                            "count": 323788,
                                                            "is_parallel": true,
                                                            "self": 28.60023229996026,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 28.23530890004269,
                                                                    "count": 1295152,
                                                                    "is_parallel": true,
                                                                    "self": 28.23530890004269
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 12.072443000002606,
                            "count": 27454,
                            "self": 0.6677345999953559,
                            "children": {
                                "process_trajectory": {
                                    "total": 10.755433800007237,
                                    "count": 27454,
                                    "self": 10.403128100007306,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.3523056999999312,
                                            "count": 6,
                                            "self": 0.3523056999999312
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 0.6492746000000125,
                                    "count": 1,
                                    "self": 0.47205640000004223,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 0.17721819999997024,
                                            "count": 6,
                                            "self": 0.17721819999997024
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 7.160000006933842e-05,
                    "count": 1,
                    "self": 7.160000006933842e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 851.3923587999964,
                                    "count": 23982,
                                    "is_parallel": true,
                                    "self": 1.4287852000029488,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 366.7050916999932,
                                            "count": 23982,
                                            "is_parallel": true,
                                            "self": 365.50372959999333,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 1.2013620999998764,
                                                    "count": 15,
                                                    "is_parallel": true,
                                                    "self": 1.2013620999998764
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 483.2584819000002,
                                            "count": 74,
                                            "is_parallel": true,
                                            "self": 241.79662540000143,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 241.4618564999988,
                                                    "count": 14277,
                                                    "is_parallel": true,
                                                    "self": 241.4618564999988
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.23933820000002015,
                    "count": 1,
                    "self": 0.004007300000012037,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.23533090000000811,
                            "count": 2,
                            "self": 0.23533090000000811
                        }
                    }
                }
            }
        }
    }
}