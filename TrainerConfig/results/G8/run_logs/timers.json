{
    "name": "root",
    "gauges": {
        "Generator.Policy.Entropy.mean": {
            "value": 1.034099817276001,
            "min": 1.034099817276001,
            "max": 1.3949812650680542,
            "count": 105
        },
        "Generator.Policy.Entropy.sum": {
            "value": 1016.5201416015625,
            "min": 44.639400482177734,
            "max": 1422.14208984375,
            "count": 105
        },
        "Generator.Environment.EpisodeLength.mean": {
            "value": 8.231481481481481,
            "min": 1.0,
            "max": 8.625,
            "count": 105
        },
        "Generator.Environment.EpisodeLength.sum": {
            "value": 889.0,
            "min": 2.0,
            "max": 900.0,
            "count": 105
        },
        "Generator.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 105
        },
        "Generator.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 105
        },
        "Solver.Policy.Entropy.mean": {
            "value": 0.09120284020900726,
            "min": 0.06336013972759247,
            "max": 0.2910512685775757,
            "count": 1261
        },
        "Solver.Policy.Entropy.sum": {
            "value": 94.8509521484375,
            "min": 55.970436096191406,
            "max": 294.1440734863281,
            "count": 1261
        },
        "Solver.Environment.EpisodeLength.mean": {
            "value": 132.0,
            "min": 23.272727272727273,
            "max": 133.71428571428572,
            "count": 1261
        },
        "Solver.Environment.EpisodeLength.sum": {
            "value": 1320.0,
            "min": 256.0,
            "max": 1703.0,
            "count": 1261
        },
        "Solver.Step.mean": {
            "value": 1325992.0,
            "min": 65970.0,
            "max": 1325992.0,
            "count": 1261
        },
        "Solver.Step.sum": {
            "value": 1325992.0,
            "min": 65970.0,
            "max": 1325992.0,
            "count": 1261
        },
        "Solver.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.0098243951797485,
            "min": -0.5152032375335693,
            "max": 1.0858243703842163,
            "count": 1261
        },
        "Solver.Policy.ExtrinsicValueEstimate.sum": {
            "value": 24.23578643798828,
            "min": -16.48650360107422,
            "max": 24.23578643798828,
            "count": 1261
        },
        "Solver.Environment.CumulativeReward.mean": {
            "value": 2.6632000267505647,
            "min": -0.7842000126838684,
            "max": 2.6720000335148404,
            "count": 1261
        },
        "Solver.Environment.CumulativeReward.sum": {
            "value": 26.632000267505646,
            "min": -20.757000505924225,
            "max": 34.35700035095215,
            "count": 1261
        },
        "Solver.Policy.ExtrinsicReward.mean": {
            "value": 2.6632000267505647,
            "min": -0.7842000126838684,
            "max": 2.6720000335148404,
            "count": 1261
        },
        "Solver.Policy.ExtrinsicReward.sum": {
            "value": 26.632000267505646,
            "min": -20.757000505924225,
            "max": 34.35700035095215,
            "count": 1261
        },
        "Solver.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 1261
        },
        "Solver.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 1261
        },
        "Solver.Losses.PolicyLoss.mean": {
            "value": 0.07357385649811476,
            "min": 0.04769620957085863,
            "max": 0.10035660416663934,
            "count": 208
        },
        "Solver.Losses.PolicyLoss.sum": {
            "value": 0.07357385649811476,
            "min": 0.04769620957085863,
            "max": 0.10035660416663934,
            "count": 208
        },
        "Solver.Losses.ValueLoss.mean": {
            "value": 0.0235525889438577,
            "min": 0.019450689336129773,
            "max": 0.20736582887669405,
            "count": 208
        },
        "Solver.Losses.ValueLoss.sum": {
            "value": 0.0235525889438577,
            "min": 0.019450689336129773,
            "max": 0.20736582887669405,
            "count": 208
        },
        "Solver.Policy.LearningRate.mean": {
            "value": 7.398997533999906e-07,
            "min": 7.398997533999906e-07,
            "max": 0.00025932961355679997,
            "count": 208
        },
        "Solver.Policy.LearningRate.sum": {
            "value": 7.398997533999906e-07,
            "min": 7.398997533999906e-07,
            "max": 0.00025932961355679997,
            "count": 208
        },
        "Solver.Policy.Epsilon.mean": {
            "value": 0.1002466,
            "min": 0.1002466,
            "max": 0.1864432,
            "count": 208
        },
        "Solver.Policy.Epsilon.sum": {
            "value": 0.1002466,
            "min": 0.1002466,
            "max": 0.1864432,
            "count": 208
        },
        "Solver.Policy.Beta.mean": {
            "value": 2.2305339999999845e-05,
            "min": 2.2305339999999845e-05,
            "max": 0.00432351568,
            "count": 208
        },
        "Solver.Policy.Beta.sum": {
            "value": 2.2305339999999845e-05,
            "min": 2.2305339999999845e-05,
            "max": 0.00432351568,
            "count": 208
        },
        "Generator.Step.mean": {
            "value": 108991.0,
            "min": 5999.0,
            "max": 108991.0,
            "count": 104
        },
        "Generator.Step.sum": {
            "value": 108991.0,
            "min": 5999.0,
            "max": 108991.0,
            "count": 104
        },
        "Generator.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.8650516271591187,
            "min": 0.25640949606895447,
            "max": 0.9539522528648376,
            "count": 104
        },
        "Generator.Policy.ExtrinsicValueEstimate.sum": {
            "value": 93.42557525634766,
            "min": 63.465370178222656,
            "max": 111.790771484375,
            "count": 104
        },
        "Generator.Environment.CumulativeReward.mean": {
            "value": 1.4180788692362882,
            "min": 0.37157231530349843,
            "max": 1.505385346153629,
            "count": 104
        },
        "Generator.Environment.CumulativeReward.sum": {
            "value": 153.15251787751913,
            "min": 106.64125449210405,
            "max": 161.07623203843832,
            "count": 104
        },
        "Generator.Policy.ExtrinsicReward.mean": {
            "value": 1.4180788692362882,
            "min": 0.37157231530349843,
            "max": 1.505385346153629,
            "count": 104
        },
        "Generator.Policy.ExtrinsicReward.sum": {
            "value": 153.15251787751913,
            "min": 106.64125449210405,
            "max": 161.07623203843832,
            "count": 104
        },
        "Generator.Losses.PolicyLoss.mean": {
            "value": 0.07529451581649482,
            "min": 0.055179847377985425,
            "max": 0.08195338277315993,
            "count": 50
        },
        "Generator.Losses.PolicyLoss.sum": {
            "value": 0.07529451581649482,
            "min": 0.055179847377985425,
            "max": 0.08195338277315993,
            "count": 50
        },
        "Generator.Losses.ValueLoss.mean": {
            "value": 0.12214193089554708,
            "min": 0.10848315386101604,
            "max": 0.2082139446089665,
            "count": 50
        },
        "Generator.Losses.ValueLoss.sum": {
            "value": 0.12214193089554708,
            "min": 0.10848315386101604,
            "max": 0.2082139446089665,
            "count": 50
        },
        "Generator.Policy.LearningRate.mean": {
            "value": 0.0007982763042154621,
            "min": 0.0007982763042154621,
            "max": 0.0007998872480140942,
            "count": 50
        },
        "Generator.Policy.LearningRate.sum": {
            "value": 0.0007982763042154621,
            "min": 0.0007982763042154621,
            "max": 0.0007998872480140942,
            "count": 50
        },
        "Generator.Policy.Epsilon.mean": {
            "value": 0.19978453800000004,
            "min": 0.19978453800000004,
            "max": 0.19998590600000002,
            "count": 50
        },
        "Generator.Policy.Epsilon.sum": {
            "value": 0.19978453800000004,
            "min": 0.19978453800000004,
            "max": 0.19998590600000002,
            "count": 50
        },
        "Generator.Policy.Beta.mean": {
            "value": 0.004989248446200001,
            "min": 0.004989248446200001,
            "max": 0.0049992967094,
            "count": 50
        },
        "Generator.Policy.Beta.sum": {
            "value": 0.004989248446200001,
            "min": 0.004989248446200001,
            "max": 0.0049992967094,
            "count": 50
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1682341101",
        "python_version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]",
        "command_line_arguments": "/home/bears_bears/Unity_env/bin/mlagents-learn ARLPCG.yaml --run-id G8 --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cu102",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1682344015"
    },
    "total": 2914.0844339190007,
    "count": 1,
    "self": 0.010507105998840416,
    "children": {
        "run_training.setup": {
            "total": 0.03518882800199208,
            "count": 1,
            "self": 0.03518882800199208
        },
        "TrainerController.start_learning": {
            "total": 2914.038737985,
            "count": 1,
            "self": 3.7636290669470327,
            "children": {
                "TrainerController._reset_env": {
                    "total": 11.982781284998055,
                    "count": 1,
                    "self": 11.982781284998055
                },
                "TrainerController.advance": {
                    "total": 2898.053294283054,
                    "count": 114535,
                    "self": 4.654769021934044,
                    "children": {
                        "env_step": {
                            "total": 2494.1830556367677,
                            "count": 114535,
                            "self": 2218.4142816833046,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 273.6032171111874,
                                    "count": 114535,
                                    "self": 15.771008201620134,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 257.83220890956727,
                                            "count": 131508,
                                            "self": 257.83220890956727
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.1655568422756915,
                                    "count": 114535,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 2908.3254198576797,
                                            "count": 114535,
                                            "is_parallel": true,
                                            "self": 921.3395944725016,
                                            "children": {
                                                "run_training.setup": {
                                                    "total": 0.0,
                                                    "count": 0,
                                                    "is_parallel": true,
                                                    "self": 0.0,
                                                    "children": {
                                                        "steps_from_proto": {
                                                            "total": 0.0017080059988074936,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0007129449913918506,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.000995061007415643,
                                                                    "count": 6,
                                                                    "is_parallel": true,
                                                                    "self": 0.000995061007415643
                                                                }
                                                            }
                                                        },
                                                        "UnityEnvironment.step": {
                                                            "total": 0.07265448300313437,
                                                            "count": 1,
                                                            "is_parallel": true,
                                                            "self": 0.0003965090072597377,
                                                            "children": {
                                                                "UnityEnvironment._generate_step_input": {
                                                                    "total": 0.0007429859979311004,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.0007429859979311004
                                                                },
                                                                "communicator.exchange": {
                                                                    "total": 0.07004812099694391,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.07004812099694391
                                                                },
                                                                "steps_from_proto": {
                                                                    "total": 0.0014668670009996276,
                                                                    "count": 2,
                                                                    "is_parallel": true,
                                                                    "self": 0.0006157509997137822,
                                                                    "children": {
                                                                        "_process_rank_one_or_two_observation": {
                                                                            "total": 0.0008511160012858454,
                                                                            "count": 6,
                                                                            "is_parallel": true,
                                                                            "self": 0.0008511160012858454
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1986.985825385178,
                                                    "count": 114534,
                                                    "is_parallel": true,
                                                    "self": 34.677161428218824,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 37.27936527076963,
                                                            "count": 114534,
                                                            "is_parallel": true,
                                                            "self": 37.27936527076963
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1818.8423614689818,
                                                            "count": 114534,
                                                            "is_parallel": true,
                                                            "self": 1818.8423614689818
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 96.18693721720774,
                                                            "count": 229068,
                                                            "is_parallel": true,
                                                            "self": 42.62851859921648,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 53.558418617991265,
                                                                    "count": 687204,
                                                                    "is_parallel": true,
                                                                    "self": 53.558418617991265
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 399.2154696243524,
                            "count": 229070,
                            "self": 8.155509233871271,
                            "children": {
                                "process_trajectory": {
                                    "total": 181.9578813855005,
                                    "count": 229070,
                                    "self": 179.70025072049248,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 2.257630665008037,
                                            "count": 27,
                                            "self": 2.257630665008037
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 209.10207900498062,
                                    "count": 258,
                                    "self": 97.81561932489421,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 111.28645968008641,
                                            "count": 12393,
                                            "self": 111.28645968008641
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 2.3220018192660064e-06,
                    "count": 1,
                    "self": 2.3220018192660064e-06
                },
                "TrainerController._save_models": {
                    "total": 0.23903102799886256,
                    "count": 1,
                    "self": 0.001321540999924764,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.2377094869989378,
                            "count": 2,
                            "self": 0.2377094869989378
                        }
                    }
                }
            }
        }
    }
}