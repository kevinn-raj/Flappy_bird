{
    "name": "root",
    "gauges": {
        "Solver.Policy.Entropy.mean": {
            "value": 0.1015917956829071,
            "min": 0.08347999304533005,
            "max": 0.12052588164806366,
            "count": 473
        },
        "Solver.Policy.Entropy.sum": {
            "value": 97.52812194824219,
            "min": 52.091514587402344,
            "max": 160.556396484375,
            "count": 473
        },
        "Solver.Environment.EpisodeLength.mean": {
            "value": 105.44444444444444,
            "min": 21.0,
            "max": 124.0,
            "count": 473
        },
        "Solver.Environment.EpisodeLength.sum": {
            "value": 949.0,
            "min": 21.0,
            "max": 1799.0,
            "count": 473
        },
        "Solver.Step.mean": {
            "value": 1111950.0,
            "min": 639964.0,
            "max": 1111950.0,
            "count": 473
        },
        "Solver.Step.sum": {
            "value": 1111950.0,
            "min": 639964.0,
            "max": 1111950.0,
            "count": 473
        },
        "Solver.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.0758873224258423,
            "min": 1.0409092903137207,
            "max": 1.0942349433898926,
            "count": 473
        },
        "Solver.Policy.ExtrinsicValueEstimate.sum": {
            "value": 18.290084838867188,
            "min": 14.788615226745605,
            "max": 22.940614700317383,
            "count": 473
        },
        "Solver.Environment.CumulativeReward.mean": {
            "value": 2.1611250191926956,
            "min": -0.7940000295639038,
            "max": 2.621545520695773,
            "count": 473
        },
        "Solver.Environment.CumulativeReward.sum": {
            "value": 17.289000153541565,
            "min": -0.7940000295639038,
            "max": 41.1130006313324,
            "count": 473
        },
        "Solver.Policy.ExtrinsicReward.mean": {
            "value": 2.1611250191926956,
            "min": -0.7940000295639038,
            "max": 2.621545520695773,
            "count": 473
        },
        "Solver.Policy.ExtrinsicReward.sum": {
            "value": 17.289000153541565,
            "min": -0.7940000295639038,
            "max": 41.1130006313324,
            "count": 473
        },
        "Solver.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 473
        },
        "Solver.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 473
        },
        "Generator.Policy.Entropy.mean": {
            "value": 1.1750835180282593,
            "min": 1.1744405031204224,
            "max": 1.189703106880188,
            "count": 41
        },
        "Generator.Policy.Entropy.sum": {
            "value": 1190.359619140625,
            "min": 810.1878051757812,
            "max": 1247.99853515625,
            "count": 41
        },
        "Generator.Environment.EpisodeLength.mean": {
            "value": 8.485714285714286,
            "min": 8.00909090909091,
            "max": 8.93939393939394,
            "count": 41
        },
        "Generator.Environment.EpisodeLength.sum": {
            "value": 891.0,
            "min": 578.0,
            "max": 910.0,
            "count": 41
        },
        "Generator.Step.mean": {
            "value": 99993.0,
            "min": 59991.0,
            "max": 99993.0,
            "count": 41
        },
        "Generator.Step.sum": {
            "value": 99993.0,
            "min": 59991.0,
            "max": 99993.0,
            "count": 41
        },
        "Generator.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.8015565872192383,
            "min": 0.7202839255332947,
            "max": 0.9404715299606323,
            "count": 41
        },
        "Generator.Policy.ExtrinsicValueEstimate.sum": {
            "value": 84.16344451904297,
            "min": 56.077842712402344,
            "max": 98.74951171875,
            "count": 41
        },
        "Generator.Environment.CumulativeReward.mean": {
            "value": 1.3694116464682988,
            "min": 1.2396965523335066,
            "max": 1.5348248639527489,
            "count": 41
        },
        "Generator.Environment.CumulativeReward.sum": {
            "value": 143.78822287917137,
            "min": 93.52105963975191,
            "max": 158.55386421084404,
            "count": 41
        },
        "Generator.Policy.ExtrinsicReward.mean": {
            "value": 1.3694116464682988,
            "min": 1.2396965523335066,
            "max": 1.5348248639527489,
            "count": 41
        },
        "Generator.Policy.ExtrinsicReward.sum": {
            "value": 143.78822287917137,
            "min": 93.52105963975191,
            "max": 158.55386421084404,
            "count": 41
        },
        "Generator.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 41
        },
        "Generator.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 41
        },
        "Generator.Losses.PolicyLoss.mean": {
            "value": 0.05604547770235513,
            "min": 0.055450979140005074,
            "max": 0.0814922674690024,
            "count": 19
        },
        "Generator.Losses.PolicyLoss.sum": {
            "value": 0.05604547770235513,
            "min": 0.055450979140005074,
            "max": 0.0814922674690024,
            "count": 19
        },
        "Generator.Losses.ValueLoss.mean": {
            "value": 0.14144153473898768,
            "min": 0.13177083525806665,
            "max": 0.14906326991816363,
            "count": 19
        },
        "Generator.Losses.ValueLoss.sum": {
            "value": 0.14144153473898768,
            "min": 0.13177083525806665,
            "max": 0.14906326991816363,
            "count": 19
        },
        "Generator.Policy.LearningRate.mean": {
            "value": 1.3048098369000038e-05,
            "min": 1.3048098369000038e-05,
            "max": 0.000308704061412,
            "count": 19
        },
        "Generator.Policy.LearningRate.sum": {
            "value": 1.3048098369000038e-05,
            "min": 1.3048098369000038e-05,
            "max": 0.000308704061412,
            "count": 19
        },
        "Generator.Policy.Epsilon.mean": {
            "value": 0.10163100000000001,
            "min": 0.10163100000000001,
            "max": 0.13858800000000002,
            "count": 19
        },
        "Generator.Policy.Epsilon.sum": {
            "value": 0.10163100000000001,
            "min": 0.10163100000000001,
            "max": 0.13858800000000002,
            "count": 19
        },
        "Generator.Policy.Beta.mean": {
            "value": 2.6146900000000043e-05,
            "min": 2.6146900000000043e-05,
            "max": 0.0003920212,
            "count": 19
        },
        "Generator.Policy.Beta.sum": {
            "value": 2.6146900000000043e-05,
            "min": 2.6146900000000043e-05,
            "max": 0.0003920212,
            "count": 19
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1682358196",
        "python_version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]",
        "command_line_arguments": "/home/bears_bears/Unity_env/bin/mlagents-learn ARLPCG.yaml --run-id ARL_v0.62_newsensors --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cu102",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1682359258"
    },
    "total": 1062.6025198409989,
    "count": 1,
    "self": 0.01621070200781105,
    "children": {
        "run_training.setup": {
            "total": 0.030831010997644626,
            "count": 1,
            "self": 0.030831010997644626
        },
        "TrainerController.start_learning": {
            "total": 1062.5554781279934,
            "count": 1,
            "self": 1.2889264286859543,
            "children": {
                "TrainerController._reset_env": {
                    "total": 13.63459021000017,
                    "count": 1,
                    "self": 13.63459021000017
                },
                "TrainerController.advance": {
                    "total": 1047.4911789453108,
                    "count": 42447,
                    "self": 1.7032641709956806,
                    "children": {
                        "env_step": {
                            "total": 962.6071124929513,
                            "count": 42447,
                            "self": 866.4111924627723,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 95.47272755789163,
                                    "count": 42447,
                                    "self": 5.514074790793529,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 89.9586527670981,
                                            "count": 48827,
                                            "self": 89.9586527670981
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.7231924722873373,
                                    "count": 42447,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1060.2997144490728,
                                            "count": 42447,
                                            "is_parallel": true,
                                            "self": 276.6286893980796,
                                            "children": {
                                                "run_training.setup": {
                                                    "total": 0.0,
                                                    "count": 0,
                                                    "is_parallel": true,
                                                    "self": 0.0,
                                                    "children": {
                                                        "steps_from_proto": {
                                                            "total": 0.0017106799932662398,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0006299219894572161,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.0010807580038090236,
                                                                    "count": 8,
                                                                    "is_parallel": true,
                                                                    "self": 0.0010807580038090236
                                                                }
                                                            }
                                                        },
                                                        "UnityEnvironment.step": {
                                                            "total": 0.10656015099812066,
                                                            "count": 1,
                                                            "is_parallel": true,
                                                            "self": 0.0002815249972627498,
                                                            "children": {
                                                                "UnityEnvironment._generate_step_input": {
                                                                    "total": 0.0005760249987361021,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.0005760249987361021
                                                                },
                                                                "communicator.exchange": {
                                                                    "total": 0.1048296279986971,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.1048296279986971
                                                                },
                                                                "steps_from_proto": {
                                                                    "total": 0.0008729730034247041,
                                                                    "count": 2,
                                                                    "is_parallel": true,
                                                                    "self": 0.00030417599191423506,
                                                                    "children": {
                                                                        "_process_rank_one_or_two_observation": {
                                                                            "total": 0.000568797011510469,
                                                                            "count": 8,
                                                                            "is_parallel": true,
                                                                            "self": 0.000568797011510469
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 783.6710250509932,
                                                    "count": 42446,
                                                    "is_parallel": true,
                                                    "self": 14.514010184873769,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 14.050793749731383,
                                                            "count": 42446,
                                                            "is_parallel": true,
                                                            "self": 14.050793749731383
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 714.1888212132326,
                                                            "count": 42446,
                                                            "is_parallel": true,
                                                            "self": 714.1888212132326
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 40.917399903155456,
                                                            "count": 84892,
                                                            "is_parallel": true,
                                                            "self": 15.490375653433148,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 25.427024249722308,
                                                                    "count": 339568,
                                                                    "is_parallel": true,
                                                                    "self": 25.427024249722308
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 83.18080228136387,
                            "count": 84894,
                            "self": 3.0649945219702204,
                            "children": {
                                "process_trajectory": {
                                    "total": 65.3934131444039,
                                    "count": 84894,
                                    "self": 64.21993051439495,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 1.173482630008948,
                                            "count": 15,
                                            "self": 1.173482630008948
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 14.722394614989753,
                                    "count": 19,
                                    "self": 6.75451557910128,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 7.967879035888473,
                                            "count": 912,
                                            "self": 7.967879035888473
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.1779993656091392e-06,
                    "count": 1,
                    "self": 1.1779993656091392e-06
                },
                "TrainerController._save_models": {
                    "total": 0.14078136599709978,
                    "count": 1,
                    "self": 0.001420091990439687,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.1393612740066601,
                            "count": 2,
                            "self": 0.1393612740066601
                        }
                    }
                }
            }
        }
    }
}