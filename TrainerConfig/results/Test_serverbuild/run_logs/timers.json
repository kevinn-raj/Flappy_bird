{
    "name": "root",
    "gauges": {
        "Solver.Policy.Entropy.mean": {
            "value": 0.08816123753786087,
            "min": 0.08816123753786087,
            "max": 0.35337400436401367,
            "count": 131
        },
        "Solver.Policy.Entropy.sum": {
            "value": 115.40306091308594,
            "min": 79.28968811035156,
            "max": 542.782470703125,
            "count": 131
        },
        "Solver.Environment.EpisodeLength.mean": {
            "value": 62.94736842105263,
            "min": 27.486486486486488,
            "max": 86.5,
            "count": 131
        },
        "Solver.Environment.EpisodeLength.sum": {
            "value": 1196.0,
            "min": 476.0,
            "max": 1506.0,
            "count": 131
        },
        "Solver.Step.mean": {
            "value": 159971.0,
            "min": 29980.0,
            "max": 159971.0,
            "count": 131
        },
        "Solver.Step.sum": {
            "value": 159971.0,
            "min": 29980.0,
            "max": 159971.0,
            "count": 131
        },
        "Solver.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.5234605669975281,
            "min": -0.5966348648071289,
            "max": 0.5535092949867249,
            "count": 131
        },
        "Solver.Policy.ExtrinsicValueEstimate.sum": {
            "value": 13.60997486114502,
            "min": -19.726978302001953,
            "max": 13.60997486114502,
            "count": 131
        },
        "Solver.Environment.CumulativeReward.mean": {
            "value": 0.6028947202782882,
            "min": -0.7090000016348702,
            "max": 1.5242727507244458,
            "count": 131
        },
        "Solver.Environment.CumulativeReward.sum": {
            "value": 11.454999685287476,
            "min": -24.81500005722046,
            "max": 23.444000005722046,
            "count": 131
        },
        "Solver.Policy.ExtrinsicReward.mean": {
            "value": 0.6028947202782882,
            "min": -0.7090000016348702,
            "max": 1.5242727507244458,
            "count": 131
        },
        "Solver.Policy.ExtrinsicReward.sum": {
            "value": 11.454999685287476,
            "min": -24.81500005722046,
            "max": 23.444000005722046,
            "count": 131
        },
        "Solver.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 131
        },
        "Solver.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 131
        },
        "Solver.Losses.PolicyLoss.mean": {
            "value": 0.06871150752219062,
            "min": 0.05910161564437052,
            "max": 0.08747357547205563,
            "count": 62
        },
        "Solver.Losses.PolicyLoss.sum": {
            "value": 0.06871150752219062,
            "min": 0.05910161564437052,
            "max": 0.08747357547205563,
            "count": 62
        },
        "Solver.Losses.ValueLoss.mean": {
            "value": 0.1632388437477251,
            "min": 0.027947990999867518,
            "max": 0.19263871169338623,
            "count": 62
        },
        "Solver.Losses.ValueLoss.sum": {
            "value": 0.1632388437477251,
            "min": 0.027947990999867518,
            "max": 0.19263871169338623,
            "count": 62
        },
        "Solver.Policy.LearningRate.mean": {
            "value": 0.00020521443159520004,
            "min": 0.00020521443159520004,
            "max": 0.0002813394062202,
            "count": 62
        },
        "Solver.Policy.LearningRate.sum": {
            "value": 0.00020521443159520004,
            "min": 0.00020521443159520004,
            "max": 0.0002813394062202,
            "count": 62
        },
        "Solver.Policy.Epsilon.mean": {
            "value": 0.16840480000000002,
            "min": 0.16840480000000002,
            "max": 0.19377979999999997,
            "count": 62
        },
        "Solver.Policy.Epsilon.sum": {
            "value": 0.16840480000000002,
            "min": 0.16840480000000002,
            "max": 0.19377979999999997,
            "count": 62
        },
        "Solver.Policy.Beta.mean": {
            "value": 0.0034233995200000007,
            "min": 0.0034233995200000007,
            "max": 0.00468961202,
            "count": 62
        },
        "Solver.Policy.Beta.sum": {
            "value": 0.0034233995200000007,
            "min": 0.0034233995200000007,
            "max": 0.00468961202,
            "count": 62
        },
        "Generator.Policy.Entropy.mean": {
            "value": 1.3647030591964722,
            "min": 1.3647030591964722,
            "max": 1.4292545318603516,
            "count": 13
        },
        "Generator.Policy.Entropy.sum": {
            "value": 1348.32666015625,
            "min": 879.7418823242188,
            "max": 1473.986328125,
            "count": 13
        },
        "Generator.Environment.EpisodeLength.mean": {
            "value": 6.3161764705882355,
            "min": 2.1785714285714284,
            "max": 6.3161764705882355,
            "count": 13
        },
        "Generator.Environment.EpisodeLength.sum": {
            "value": 859.0,
            "min": 366.0,
            "max": 863.0,
            "count": 13
        },
        "Generator.Step.mean": {
            "value": 14995.0,
            "min": 2998.0,
            "max": 14995.0,
            "count": 13
        },
        "Generator.Step.sum": {
            "value": 14995.0,
            "min": 2998.0,
            "max": 14995.0,
            "count": 13
        },
        "Generator.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.571264922618866,
            "min": -0.5490379929542542,
            "max": 0.571264922618866,
            "count": 13
        },
        "Generator.Policy.ExtrinsicValueEstimate.sum": {
            "value": 77.69203186035156,
            "min": -142.20083618164062,
            "max": 91.4421615600586,
            "count": 13
        },
        "Generator.Environment.CumulativeReward.mean": {
            "value": 1.029556754974799,
            "min": 0.33168361005847324,
            "max": 1.029556754974799,
            "count": 13
        },
        "Generator.Environment.CumulativeReward.sum": {
            "value": 140.01971867657267,
            "min": 55.391162879765034,
            "max": 140.01971867657267,
            "count": 13
        },
        "Generator.Policy.ExtrinsicReward.mean": {
            "value": 1.029556754974799,
            "min": 0.33168361005847324,
            "max": 1.029556754974799,
            "count": 13
        },
        "Generator.Policy.ExtrinsicReward.sum": {
            "value": 140.01971867657267,
            "min": 55.391162879765034,
            "max": 140.01971867657267,
            "count": 13
        },
        "Generator.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 13
        },
        "Generator.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 13
        },
        "Generator.Losses.PolicyLoss.mean": {
            "value": 0.0615336987975752,
            "min": 0.05952712231858944,
            "max": 0.078153733915921,
            "count": 6
        },
        "Generator.Losses.PolicyLoss.sum": {
            "value": 0.0615336987975752,
            "min": 0.05952712231858944,
            "max": 0.078153733915921,
            "count": 6
        },
        "Generator.Losses.ValueLoss.mean": {
            "value": 0.18772280712922415,
            "min": 0.12169151054695249,
            "max": 0.19995868764817715,
            "count": 6
        },
        "Generator.Losses.ValueLoss.sum": {
            "value": 0.18772280712922415,
            "min": 0.12169151054695249,
            "max": 0.19995868764817715,
            "count": 6
        },
        "Generator.Policy.LearningRate.mean": {
            "value": 0.0006817120147859999,
            "min": 0.0006817120147859999,
            "max": 0.000763848004519,
            "count": 6
        },
        "Generator.Policy.LearningRate.sum": {
            "value": 0.0006817120147859999,
            "min": 0.0006817120147859999,
            "max": 0.000763848004519,
            "count": 6
        },
        "Generator.Policy.Epsilon.mean": {
            "value": 0.18521400000000002,
            "min": 0.18521400000000002,
            "max": 0.19548100000000002,
            "count": 6
        },
        "Generator.Policy.Epsilon.sum": {
            "value": 0.18521400000000002,
            "min": 0.18521400000000002,
            "max": 0.19548100000000002,
            "count": 6
        },
        "Generator.Policy.Beta.mean": {
            "value": 0.0008536185999999999,
            "min": 0.0008536185999999999,
            "max": 0.0009552619000000002,
            "count": 6
        },
        "Generator.Policy.Beta.sum": {
            "value": 0.0008536185999999999,
            "min": 0.0008536185999999999,
            "max": 0.0009552619000000002,
            "count": 6
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1682443362",
        "python_version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]",
        "command_line_arguments": "/home/bears_bears/Unity_env/bin/mlagents-learn ARLPCG.yaml --env ../Builds/Linux_server/1/Flappy_bird_RL.x86_64 --num-envs 30 --run-id Test_serverbuild --no-graphics --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cu102",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1682444255"
    },
    "total": 893.692273644001,
    "count": 1,
    "self": 2.5849074970010406,
    "children": {
        "run_training.setup": {
            "total": 0.6380707059997803,
            "count": 1,
            "self": 0.6380707059997803
        },
        "TrainerController.start_learning": {
            "total": 890.4692954410002,
            "count": 1,
            "self": 0.8979207399497682,
            "children": {
                "TrainerController._reset_env": {
                    "total": 16.089956579999125,
                    "count": 1,
                    "self": 16.089956579999125
                },
                "TrainerController.advance": {
                    "total": 870.6518139960499,
                    "count": 4701,
                    "self": 0.31018638487330463,
                    "children": {
                        "env_step": {
                            "total": 760.5528551621082,
                            "count": 4701,
                            "self": 133.9541862133392,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 625.3383622337533,
                                    "count": 140759,
                                    "self": 27.12957727889261,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 598.2087849548607,
                                            "count": 145344,
                                            "self": 598.2087849548607
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.2603067150157585,
                                    "count": 4701,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 26622.19722017531,
                                            "count": 140759,
                                            "is_parallel": true,
                                            "self": 25779.506938062103,
                                            "children": {
                                                "run_training.setup": {
                                                    "total": 0.0,
                                                    "count": 0,
                                                    "is_parallel": true,
                                                    "self": 0.0,
                                                    "children": {
                                                        "steps_from_proto": {
                                                            "total": 0.0908507129897771,
                                                            "count": 60,
                                                            "is_parallel": true,
                                                            "self": 0.04670175698447565,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.04414895600530144,
                                                                    "count": 240,
                                                                    "is_parallel": true,
                                                                    "self": 0.04414895600530144
                                                                }
                                                            }
                                                        },
                                                        "UnityEnvironment.step": {
                                                            "total": 8.642908960991917,
                                                            "count": 30,
                                                            "is_parallel": true,
                                                            "self": 0.00732998098283133,
                                                            "children": {
                                                                "UnityEnvironment._generate_step_input": {
                                                                    "total": 0.010578043998975772,
                                                                    "count": 30,
                                                                    "is_parallel": true,
                                                                    "self": 0.010578043998975772
                                                                },
                                                                "communicator.exchange": {
                                                                    "total": 8.596559408004396,
                                                                    "count": 30,
                                                                    "is_parallel": true,
                                                                    "self": 8.596559408004396
                                                                },
                                                                "steps_from_proto": {
                                                                    "total": 0.028441528005714645,
                                                                    "count": 60,
                                                                    "is_parallel": true,
                                                                    "self": 0.015247338011249667,
                                                                    "children": {
                                                                        "_process_rank_one_or_two_observation": {
                                                                            "total": 0.013194189994464978,
                                                                            "count": 240,
                                                                            "is_parallel": true,
                                                                            "self": 0.013194189994464978
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 842.6902821132062,
                                                    "count": 140729,
                                                    "is_parallel": true,
                                                    "self": 38.00072801123497,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 20.86214354621916,
                                                            "count": 140729,
                                                            "is_parallel": true,
                                                            "self": 20.86214354621916
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 654.8815656070128,
                                                            "count": 140729,
                                                            "is_parallel": true,
                                                            "self": 654.8815656070128
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 128.94584494873925,
                                                            "count": 281458,
                                                            "is_parallel": true,
                                                            "self": 67.28961513594368,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 61.65622981279557,
                                                                    "count": 1125832,
                                                                    "is_parallel": true,
                                                                    "self": 61.65622981279557
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 109.78877244906835,
                            "count": 9401,
                            "self": 0.5985296532071516,
                            "children": {
                                "process_trajectory": {
                                    "total": 30.80473394886576,
                                    "count": 9401,
                                    "self": 30.154919591868747,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.6498143569970125,
                                            "count": 4,
                                            "self": 0.6498143569970125
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 78.38550884699544,
                                    "count": 69,
                                    "self": 39.05604139698153,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 39.32946745001391,
                                            "count": 3275,
                                            "self": 39.32946745001391
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 2.175000190618448e-06,
                    "count": 1,
                    "self": 2.175000190618448e-06
                },
                "TrainerController._save_models": {
                    "total": 2.8296019500012335,
                    "count": 1,
                    "self": 0.002462420001393184,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 2.8271395299998403,
                            "count": 2,
                            "self": 2.8271395299998403
                        }
                    }
                }
            }
        }
    }
}